DEFAULT_MAX_WINDOW_SIZE: int = 5000  
DEFAULT_MIN_WINDOW_SIZE: int = 2000  
DEFAULT_INIT_WINDOW_SIZE: int = 1000  

# Whole data set  

lc: float = 0  # lower coverage threshold of N/S  
hc: float = 0.17 / 99.83 * 3  # higher coverage threshold of N/S  
pacc: float = 0.99  # threshold of predict accuracy  
prec: float = 0.85  # threshold of predict recall  

Training set: size -- 227844  
  window size = 2079  
  accuracy = 0.9842227071348277  
  recall = 0.8313253012048193  
  
TP = 345, FN = 70, TN = 222921, FP = 3509  

Testing set: size -- 56962  
  Confusion matrix:  
    [[55347  1540]  
     [   13    62]]  
     
  Report:  
                  precision    recall  f1-score   support  
               0       1.00      0.97      0.99     56887  
               1       0.04      0.83      0.07        75  
        accuracy                           0.97     56962  
       macro avg       0.52      0.90      0.53     56962  
    weighted avg       1.00      0.97      0.98     56962  
    
  AUC score of ROC curve: 0.8997977276589262  
  ROC curve stored in: ./images/dt_roc_result21.jpg
