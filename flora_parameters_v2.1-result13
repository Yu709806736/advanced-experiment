DEFAULT_MIN_WINDOW_SIZE: int = 5000
DEFAULT_MIN_WINDOW_SIZE: int = 2000
DEFAULT_INIT_WINDOW_SIZE: int = 500

SMOTE --> 0.1
min_pos_por: 0.2
min_neg_por: 0.5

# Whole data set

lc: float = 0  # lower coverage threshold of N/S
hc: float = 0.17 / 99.83 * 3  # higher coverage threshold of N/S
pacc: float = 0.99  # threshold of predict accuracy
prec: float = 0.83  # threshold of predict recall

Training set: size -- 227844
  window size = 1999
  accuracy = 0.9922617855569351
  recall = 0.9654383959194442
  
Testing set: size -- 56962
  Confusion matrix:
    [[56668   219]
     [   17    58]]
     
  Report:
                  precision    recall  f1-score   support
               0       1.00      1.00      1.00     56887
               1       0.21      0.77      0.33        75
        accuracy                           1.00     56962
       macro avg       0.60      0.88      0.66     56962
    weighted avg       1.00      1.00      1.00     56962
    
  AUC score of ROC curve: 0.884741798067514
  
  ROC curve stored in test3.jpg
