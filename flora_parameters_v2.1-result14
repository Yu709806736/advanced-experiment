DEFAULT_MIN_WINDOW_SIZE: int = 5000
DEFAULT_MIN_WINDOW_SIZE: int = 2000
DEFAULT_INIT_WINDOW_SIZE: int = 500

SMOTE --> 0.05
min_pos_por: 0.2
min_neg_por: 0.5

# Whole data set

lc: float = 0  # lower coverage threshold of N/S
hc: float = 0.17 / 99.83 * 3  # higher coverage threshold of N/S
pacc: float = 0.99  # threshold of predict accuracy
prec: float = 0.83  # threshold of predict recall

Training set: size -- 272912
  window size = 1999
  accuracy = 0.9924674463594052
  recall = 0.9574355817430306
  
Testing set: size -- 56962
  Confusion matrix:
    [[56413   474]
     [   15    60]]
     
  Report:
                  precision    recall  f1-score   support
               0       1.00      0.99      1.00     56887
               1       0.11      0.80      0.20        75
        accuracy                           0.99     56962
       macro avg       0.56      0.90      0.60     56962
    weighted avg       1.00      0.99      0.99     56962
    
  AUC score of ROC curve: 0.8958338460456695
  
  ROC curve stored in test4.jpg
